{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c13bab",
   "metadata": {},
   "source": [
    "# Costa Rican Household Poverty Level Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa20022",
   "metadata": {},
   "source": [
    "- ê°€êµ¬ë³„ ê°€ë‚œ ë“±ê¸‰...?ì„ ì˜ˆì¸¡\n",
    "  - 1: extreme poverty / 2: moderate poverty / 3: vulnerable households / non vulnerabel households\n",
    "- ê° ê°€êµ¬ì›ë³„ë¡œ ì¹¼ëŸ¼ì´ ìˆì§€ë§Œ predictionì€ ê°€ì¥ì˜ rowì— ëŒ€í•´ì„œë§Œ ë„ì¶œ\n",
    "- í‰ê°€ ì§€í‘œ: macro F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f086df",
   "metadata": {},
   "source": [
    "#### ë³€ìˆ˜ ì„¤ëª…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb447d",
   "metadata": {},
   "source": [
    "- v2a1, Monthly rent payment  \n",
    "- hacdor, =1 Overcrowding by bedrooms\n",
    "- rooms,  number of all rooms in the house\n",
    "- hacapo, =1 Overcrowding by rooms\n",
    "- v14a, =1 has bathroom in the household\n",
    "- refrig, =1 if the household has refrigerator\n",
    "- v18q, owns a tablet\n",
    "- v18q1, number of tablets household owns\n",
    "- r4h1, Males younger than 12 years of age\n",
    "- r4h2, Males 12 years of age and older\n",
    "- r4h3, Total males in the household\n",
    "- r4m1, Females younger than 12 years of age\n",
    "- r4m2, Females 12 years of age and older\n",
    "- r4m3, Total females in the household\n",
    "- r4t1, persons younger than 12 years of age\n",
    "- r4t2, persons 12 years of age and older\n",
    "- r4t3, Total persons in the household\n",
    "- tamhog, size of the household\n",
    "- tamviv, number of persons living in the household\n",
    "- escolari, years of schooling\n",
    "- rez_esc, Years behind in school\n",
    "- hhsize, household size\n",
    "- paredblolad, =1 if predominant material on the outside wall is block or brick\n",
    "- paredzocalo, \"=1 if predominant material on the outside wall is socket (wood,  zinc or absbesto\"\n",
    "- paredpreb, =1 if predominant material on the outside wall is prefabricated or cement\n",
    "- pareddes, =1 if predominant material on the outside wall is waste material\n",
    "- paredmad, =1 if predominant material on the outside wall is wood\n",
    "- paredzinc, =1 if predominant material on the outside wall is zink\n",
    "- paredfibras, =1 if predominant material on the outside wall is natural fibers\n",
    "- paredother, =1 if predominant material on the outside wall is other\n",
    "- pisomoscer, \"=1 if predominant material on the floor is mosaic,  ceramic,  terrazo\"\n",
    "- pisocemento, =1 if predominant material on the floor is cement\n",
    "- pisoother, =1 if predominant material on the floor is other\n",
    "- pisonatur, =1 if predominant material on the floor is  natural material\n",
    "- pisonotiene, =1 if no floor at the household\n",
    "- pisomadera, =1 if predominant material on the floor is wood\n",
    "- techozinc, =1 if predominant material on the roof is metal foil or zink\n",
    "- techoentrepiso, \"=1 if predominant material on the roof is fiber cement,  mezzanine \"\n",
    "- techocane, =1 if predominant material on the roof is natural fibers\n",
    "- techootro, =1 if predominant material on the roof is other\n",
    "- cielorazo, =1 if the house has ceiling\n",
    "- abastaguadentro, =1 if water provision inside the dwelling\n",
    "- abastaguafuera, =1 if water provision outside the dwelling\n",
    "- abastaguano, =1 if no water provision\n",
    "- public, \"=1 electricity from CNFL,  ICE,  ESPH/JASEC\"\n",
    "- planpri, =1 electricity from private plant\n",
    "- noelec, =1 no electricity in the dwelling\n",
    "- coopele, =1 electricity from cooperative\n",
    "- sanitario1, =1 no toilet in the dwelling\n",
    "- sanitario2, =1 toilet connected to sewer or cesspool\n",
    "- sanitario3, =1 toilet connected to  septic tank\n",
    "- sanitario5, =1 toilet connected to black hole or letrine\n",
    "- sanitario6, =1 toilet connected to other system\n",
    "- energcocinar1, =1 no main source of energy used for cooking (no kitchen)\n",
    "- energcocinar2, =1 main source of energy used for cooking electricity\n",
    "- energcocinar3, =1 main source of energy used for cooking gas\n",
    "- energcocinar4, =1 main source of energy used for cooking wood charcoal\n",
    "- elimbasu1, =1 if rubbish disposal mainly by tanker truck\n",
    "- elimbasu2, =1 if rubbish disposal mainly by botan hollow or buried\n",
    "- elimbasu3, =1 if rubbish disposal mainly by burning\n",
    "- elimbasu4, =1 if rubbish disposal mainly by throwing in an unoccupied space\n",
    "- elimbasu5, \"=1 if rubbish disposal mainly by throwing in river,  creek or sea\"\n",
    "- elimbasu6, =1 if rubbish disposal mainly other\n",
    "- epared1, =1 if walls are bad\n",
    "- epared2, =1 if walls are regular\n",
    "- epared3, =1 if walls are good\n",
    "- etecho1, =1 if roof are bad\n",
    "- etecho2, =1 if roof are regular\n",
    "- etecho3, =1 if roof are good\n",
    "- eviv1, =1 if floor are bad\n",
    "- eviv2, =1 if floor are regular\n",
    "- eviv3, =1 if floor are good\n",
    "- dis, =1 if disable person\n",
    "- male, =1 if male\n",
    "- female, =1 if female\n",
    "- estadocivil1, =1 if less than 10 years old\n",
    "- estadocivil2, =1 if free or coupled uunion\n",
    "- estadocivil3, =1 if married\n",
    "- estadocivil4, =1 if divorced\n",
    "- estadocivil5, =1 if separated\n",
    "- estadocivil6, =1 if widow/er\n",
    "- estadocivil7, =1 if single\n",
    "- **parentesco1, =1 if household head**\n",
    "- parentesco2, =1 if spouse/partner\n",
    "- parentesco3, =1 if son/doughter\n",
    "- parentesco4, =1 if stepson/doughter\n",
    "- parentesco5, =1 if son/doughter in law\n",
    "- parentesco6, =1 if grandson/doughter\n",
    "- parentesco7, =1 if mother/father\n",
    "- parentesco8, =1 if father/mother in law\n",
    "- parentesco9, =1 if brother/sister\n",
    "- parentesco10, =1 if brother/sister in law\n",
    "- parentesco11, =1 if other family member\n",
    "- parentesco12, =1 if other non family member\n",
    "- **idhogar, Household level identifier**\n",
    "- hogar_nin, Number of children 0 to 19 in household\n",
    "- hogar_adul, Number of adults in household\n",
    "- hogar_mayor, # of individuals 65+ in the household\n",
    "- hogar_total, # of total individuals in the household\n",
    "- dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n",
    "- edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and \n",
    "- gender, yes=1 and no=0\n",
    "- edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and  - gender, yes=1 and no=0\n",
    "- meaneduc,average years of education for adults (18+)\n",
    "- instlevel1, =1 no level of education\n",
    "- instlevel2, =1 incomplete primary\n",
    "- instlevel3, =1 complete primary\n",
    "- instlevel4, =1 incomplete academic secondary level\n",
    "- instlevel5, =1 complete academic secondary level\n",
    "- instlevel6, =1 incomplete technical secondary level\n",
    "- instlevel7, =1 complete technical secondary level\n",
    "- instlevel8, =1 undergraduate and higher education\n",
    "- instlevel9, =1 postgraduate higher education\n",
    "- bedrooms, number of bedrooms\n",
    "- overcrowding, # persons per room\n",
    "- tipovivi1, =1 own and fully paid house\n",
    "- tipovivi2, \"=1 own,  paying in installments\"\n",
    "- tipovivi3, =1 rented\n",
    "- tipovivi4, =1 precarious\n",
    "- tipovivi5, \"=1 other(assigned,  borrowed)\"\n",
    "- computer, =1 if the household has notebook or desktop computer\n",
    "- television, =1 if the household has TV\n",
    "- mobilephone, =1 if mobile phone\n",
    "- qmobilephone, # of mobile phones\n",
    "- lugar1, =1 region Central\n",
    "- lugar2, =1 region Chorotega\n",
    "- lugar3, =1 region PacÃƒÆ’Ã‚Â­fico central\n",
    "- lugar4, =1 region Brunca\n",
    "- lugar5, =1 region Huetar AtlÃƒÆ’Ã‚Â¡ntica\n",
    "- lugar6, =1 region Huetar Norte\n",
    "- area1, =1 zona urbana\n",
    "- area2, =2 zona rural\n",
    "- age, Age in years\n",
    "- SQBescolari, escolari squared\n",
    "- SQBage, age squared\n",
    "- SQBhogar_total, hogar_total squared\n",
    "- SQBedjefe, edjefe squared\n",
    "- SQBhogar_nin, hogar_nin squared\n",
    "- SQBovercrowding, overcrowding squared\n",
    "- SQBdependency, dependency squared\n",
    "- SQBmeaned, square of the mean years of education of adults (>=18) in the household\n",
    "- agesq, Age squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a381e",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d52ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayoungcho/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1ac63",
   "metadata": {},
   "source": [
    "##  ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8dc7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# target ë³€ìˆ˜ ë¼ë²¨ì¸ì½”ë”©\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])  \n",
    "\n",
    "# ë³€ìˆ˜ì¤‘ìš”ë„ ì •ë ¬\n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    if display_results:\n",
    "        print(\"Feature ranking:\")\n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print(\"%d. feature %d (%f)\" % (f+1, indices[f], importances[f]) + \"-\" + X_train.columns[indices[f]])\n",
    "        ranked_list.append(X_train.columns[indices[f]])\n",
    "\n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(X_train.columns[indices[f]])\n",
    "\n",
    "    return ranked_list, zero_features  # ë³€ìˆ˜ì¤‘ìš”ë„ ì •ë ¬í•œ ë¦¬ìŠ¤íŠ¸ / ë³€ìˆ˜ì¤‘ìš”ë„ê°€ 0ì¸ ë³€ìˆ˜ë“¤ ë¦¬ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41161ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_features(df):   # ìƒˆ ë³€ìˆ˜ ìƒì„±\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'),             # ê°€êµ¬ ë‚´ ì¸ì› ì¤‘ 12ì‚´ ë¯¸ë§Œ ì–´ë¦°ì´ì˜ ë¹„ìœ¨\n",
    "                 ('working_man_fraction', 'r4h2', 'r4t3'),          # ê°€êµ¬ ë‚´ ì¸ì› ì¤‘ 12ì‚´ ì´ˆê³¼ ë‚¨ì„±ì˜ ë¹„ìœ¨\n",
    "                 ('all_man_fraction', 'r4h3', 'r4t3'),              # ê°€êµ¬ ë‚´ ì¸ì› ì¤‘ ë‚¨ìì˜ ë¹„ìœ¨\n",
    "                 ('human_density', 'tamviv', 'rooms'),              # ê°€êµ¬ ë‚´ ì‹¤ê±°ì£¼ì¸ì› / ë°©ì˜ ê°œìˆ˜\n",
    "                 ('human_bed_density', 'tamviv', 'bedrooms'),       # ê°€êµ¬ ë‚´ ì‹¤ê±°ì£¼ì¸ì› / ì¹¨ì‹¤ì˜ ê°œìˆ˜\n",
    "                 ('rent_per_person', 'v2a1', 'r4t3'),               # 1ì¸ë‹¹ ì›”ì„¸(ì›”ì„¸ / ê°€êµ¬ ë‚´ ì¸ì›)\n",
    "                 ('rent_per_room', 'v2a1', 'rooms'),                # ë°© 1ê°œë‹¹ ì›”ì„¸(ì›”ì„¸ / ë°©ì˜ ê°œìˆ˜)\n",
    "                 ('mobile_density', 'qmobilephone', 'r4t3'),        # íœ´ëŒ€í° ê°œìˆ˜ / ê°€êµ¬ ë‚´ ì¸ì›\n",
    "                 ('tablet_density', 'v18q1', 'r4t3'),               # íƒœë¸”ë¦¿ ê°œìˆ˜ / ê°€êµ¬ ë‚´ ì¸ì›\n",
    "                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),  # íœ´ëŒ€í° ê°œìˆ˜ / 12ì„¸ ì´ìƒ ì¸ì›\n",
    "                 ('tablet_adult_density', 'v18q1', 'r4t2'),         # íƒœë¸”ë¦¿ ê°œìˆ˜ / 12ì„¸ ì´ìƒ ì¸ì›\n",
    "                ]\n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),         # ê°€êµ¬ ë‚´ ì¸ì› - ê°€êµ¬ ë‚´ ì‹¤ê±°ì£¼ì¸ì›\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "    \n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_'+f_new] = (df[f1] / df[f2]).astype(np.float32)\n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_'+f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "\n",
    "    aggs_num = {'age' : ['min', 'max', 'mean'],\n",
    "                'escolari': ['min', 'max', 'mean']}  # escolari: years of schooling\n",
    "    aggs_cat = {'dis': ['mean']}                     # dis: ì¥ì•  ì—¬ë¶€(ìˆìœ¼ë©´ 1) -> ì´ì§„ ë³€ìˆ˜ì˜ í‰ê· : ë¹„ìœ¨\n",
    "\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:           \n",
    "        # estadocivil: 10ì„¸ ë¯¸ë§Œ / ì»¤í”Œ? / ê¸°í˜¼ / ì´í˜¼ / ë³„ê±° / ë¯¸ë§ì¸ / ì†”ë¡œ  - 7ê°œì˜ ìƒíƒœë¥¼ ì›í•«ì¸ì½”ë”©ìœ¼ë¡œ 7ê°œì˜ ë³€ìˆ˜ë¡œ\n",
    "        # parentesco: ê°€ì¥ ë³¸ì¸ / ì•„ë‚´ í˜¹ì€ íŒŒíŠ¸ë„ˆ / ìì‹ / ì˜ë¶“ì•„ë“¤ í˜¹ì€ ë”¸ / ì‚¬ìœ„ í˜¹ì€ ë©°ëŠë¦¬ / ì¦ì†ì í˜¹ì€ ì¦ì†ë…€ / ì–´ë¨¸ë‹ˆ í˜¹ì€ ì•„ë²„ì§€ / ì‹œì–´ë¨¸ë‹ˆ í˜¹ì€ ì‹œì•„ë²„ì§€ / í˜•ì œ / ì²˜í˜• ì²˜ë‚¨ ë“±ë“±.. / ê·¸ ì™¸ ê°€ì¡± / ê°€ì¡± ì™¸ - 12ê°œì˜ ê°€ì¥ê³¼ì˜ ê´€ê³„ë¥¼ ì›í•«ì¸ì½”ë”©ìœ¼ë¡œ 12ê°œì˜ ë³€ìˆ˜ë¡œ ë‚˜ëˆ”\n",
    "        # instlevel: êµìœ¡X / ì´ˆë“±í•™êµ ì¤‘í‡´ / ì´ˆì¡¸ / ì¤‘í•™êµ ì¤‘í‡´ / ì¤‘ì¡¸ / ê³ ë“±í•™êµ ì¤‘í‡´ / ê³ ì¡¸ / ëŒ€í•™êµ ì¬í•™ / ëŒ€ì¡¸ - 9ê°œì˜ ìƒíƒœ\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '-' + e[0] + '-' + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0d45b",
   "metadata": {},
   "source": [
    "ğŸ“Œ ê²°ê³¼ì ìœ¼ë¡œ ìƒì„±ë˜ëŠ” í”¼ì²˜ ì˜ˆì‹œ\n",
    "- agg18-age-MIN: í•´ë‹¹ ê°€êµ¬ ë‚´ 18ì„¸ ì´ìƒ êµ¬ì„±ì›ì˜ ìµœì†Ÿê°’ ë‚˜ì´\n",
    "\n",
    "- agg18-dis-MEAN: í•´ë‹¹ ê°€êµ¬ ë‚´ 18ì„¸ ì´ìƒ ì¤‘ ì¥ì• ì¸ ë¹„ìœ¨\n",
    "\n",
    "- agg18-parentesco_1-MEAN: ê°€êµ¬ì£¼ ë³¸ì¸ ë¹„ìœ¨\n",
    "\n",
    "- agg18-instlevel_8-COUNT: ëŒ€í•™êµ ì¬í•™ ì¤‘ì¸ êµ¬ì„±ì› ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a00b3a",
   "metadata": {},
   "source": [
    "r4t3ë‘ tamvivë‘ tamhogë‘ ë­ê°€ ë‹¤ë¥¸ì§€ ëª¨ë¥´ê³˜ìŒ  \n",
    "- r4t3: total persons in the household\n",
    "- tamviv: number of persons living in the household\n",
    "- tamhog: size of the household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6d8c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>r4t3</th>\n",
       "      <th>tamviv</th>\n",
       "      <th>tamhog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>ID_cca751e53</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538</th>\n",
       "      <td>ID_bfbb06d62</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>ID_e20c78904</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>ID_e01b00c7e</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9541</th>\n",
       "      <td>ID_a31274054</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>ID_fc386a944</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9543</th>\n",
       "      <td>ID_2f8268634</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>ID_4c180d79f</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>ID_32a00a8bf</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9546</th>\n",
       "      <td>ID_1dfb12fcf</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9547</th>\n",
       "      <td>ID_198be48d1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9548</th>\n",
       "      <td>ID_9df63c33e</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>ID_aacac04a2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>ID_90a399a51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>ID_79d39dddc</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>ID_d45ae367d</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9553</th>\n",
       "      <td>ID_c94744e07</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>ID_85fc658f8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>ID_ced540c61</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>ID_a38c64491</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  r4t3  tamviv  tamhog\n",
       "9537  ID_cca751e53     5       5       5\n",
       "9538  ID_bfbb06d62     5       5       5\n",
       "9539  ID_e20c78904     5       5       5\n",
       "9540  ID_e01b00c7e     5       5       5\n",
       "9541  ID_a31274054     5       5       5\n",
       "9542  ID_fc386a944     5       5       5\n",
       "9543  ID_2f8268634     5       5       5\n",
       "9544  ID_4c180d79f     5       5       5\n",
       "9545  ID_32a00a8bf     5       7       5\n",
       "9546  ID_1dfb12fcf     5       7       5\n",
       "9547  ID_198be48d1     5       7       5\n",
       "9548  ID_9df63c33e     5       7       5\n",
       "9549  ID_aacac04a2     5       7       5\n",
       "9550  ID_90a399a51     2       2       2\n",
       "9551  ID_79d39dddc     2       2       2\n",
       "9552  ID_d45ae367d     5       5       5\n",
       "9553  ID_c94744e07     5       5       5\n",
       "9554  ID_85fc658f8     5       5       5\n",
       "9555  ID_ced540c61     5       5       5\n",
       "9556  ID_a38c64491     5       5       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/dayoungcho/Desktop/costa-rican-household-poverty-prediction/train.csv')\n",
    "train_df[['Id', 'r4t3', 'tamviv', 'tamhog']].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25974806",
   "metadata": {},
   "source": [
    "ì¶œë ¥í•´ë´ë„ ëª¨ë¥´ê² ìŒ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19d5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›í•«ì¸ì½”ë”©ëœ ë³€ìˆ˜ë“¤ì„ ë¼ë²¨ì¸ì½”ë”©í•œ í•˜ë‚˜ì˜ ë³€ìˆ˜ë¡œ í†µí•©\n",
    "\n",
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', 'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', 'instlevel', 'lugar', 'tipovivi','manual_elec']:\n",
    "        if 'manual_' not in s_:  # manual_elec ì œì™¸í•œ ë³€ìˆ˜ë“¤\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']   # ì „ê¸°ì˜ ì¶œì²˜(ë°œì „ì†Œ/ê¸°ì—… ë“±ë“±..)\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "\n",
    "        if 0 in sum_ohe:\n",
    "            print('{} ì•ˆì˜ OHEê°€ ë¶ˆì™„ì „í•˜ë¯€ë¡œ ë¼ë²¨ ì¸ì½”ë”© ì „ì— ìƒˆë¡œìš´ ì¹¼ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤'.format(s_))\n",
    "        \n",
    "            col_dummy = s_ + '_dummy'\n",
    "            tmp_df[col_dummy] = s_ + '_dummy'\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1)==0).astype(np.int8)\n",
    "            cols_s_.append(col_dummy)\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                print(\"ì œëŒ€ë¡œ ì•ˆ ë¨..\")\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)  # ìµœëŒ€ê°’ì˜ ì¸ë±ìŠ¤ ë°˜í™˜\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c746fd2",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79fba659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/dayoungcho/Desktop/costa-rican-household-poverty-prediction/train.csv')\n",
    "test = pd.read_csv('/Users/dayoungcho/Desktop/costa-rican-household-poverty-prediction/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbcae55",
   "metadata": {},
   "source": [
    "## ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0a16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    encode_data(df_)  # target ë³€ìˆ˜ ë¼ë²¨ì¸ì½”ë”©\n",
    "    return do_features(df_)  # ìƒˆë¡œìš´ ë³€ìˆ˜ë“¤ ìƒì„±\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cbc5608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>r4h2</th>\n",
       "      <th>...</th>\n",
       "      <th>agg18-instlevel5-MEAN</th>\n",
       "      <th>agg18-instlevel5-COUNT</th>\n",
       "      <th>agg18-instlevel6-MEAN</th>\n",
       "      <th>agg18-instlevel6-COUNT</th>\n",
       "      <th>agg18-instlevel7-MEAN</th>\n",
       "      <th>agg18-instlevel7-COUNT</th>\n",
       "      <th>agg18-instlevel8-MEAN</th>\n",
       "      <th>agg18-instlevel8-COUNT</th>\n",
       "      <th>agg18-instlevel9-MEAN</th>\n",
       "      <th>agg18-instlevel9-COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  r4h1  r4h2  \\\n",
       "0  190000.0       0      3       0     1       1     0    NaN     0     1   \n",
       "1  135000.0       0      4       0     1       1     1    1.0     0     1   \n",
       "2       NaN       0      8       0     1       1     0    NaN     0     0   \n",
       "3  180000.0       0      5       0     1       1     1    1.0     0     2   \n",
       "4  180000.0       0      5       0     1       1     1    1.0     0     2   \n",
       "\n",
       "   ...  agg18-instlevel5-MEAN  agg18-instlevel5-COUNT  agg18-instlevel6-MEAN  \\\n",
       "0  ...                    0.0                     1.0                    0.0   \n",
       "1  ...                    0.0                     1.0                    0.0   \n",
       "2  ...                    1.0                     1.0                    0.0   \n",
       "3  ...                    1.0                     2.0                    0.0   \n",
       "4  ...                    1.0                     2.0                    0.0   \n",
       "\n",
       "   agg18-instlevel6-COUNT  agg18-instlevel7-MEAN  agg18-instlevel7-COUNT  \\\n",
       "0                     1.0                    0.0                     1.0   \n",
       "1                     1.0                    0.0                     1.0   \n",
       "2                     1.0                    0.0                     1.0   \n",
       "3                     2.0                    0.0                     2.0   \n",
       "4                     2.0                    0.0                     2.0   \n",
       "\n",
       "   agg18-instlevel8-MEAN  agg18-instlevel8-COUNT  agg18-instlevel9-MEAN  \\\n",
       "0                    0.0                     1.0                    0.0   \n",
       "1                    1.0                     1.0                    0.0   \n",
       "2                    0.0                     1.0                    0.0   \n",
       "3                    0.0                     2.0                    0.0   \n",
       "4                    0.0                     2.0                    0.0   \n",
       "\n",
       "   agg18-instlevel9-COUNT  \n",
       "0                     1.0  \n",
       "1                     1.0  \n",
       "2                     1.0  \n",
       "3                     2.0  \n",
       "4                     2.0  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40b0805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v2a1                      6860\n",
       "hacdor                       0\n",
       "rooms                        0\n",
       "hacapo                       0\n",
       "v14a                         0\n",
       "                          ... \n",
       "agg18-instlevel7-COUNT      15\n",
       "agg18-instlevel8-MEAN       15\n",
       "agg18-instlevel8-COUNT      15\n",
       "agg18-instlevel9-MEAN       15\n",
       "agg18-instlevel9-COUNT      15\n",
       "Length: 218, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()   # ê²°ì¸¡ì¹˜ ìˆëŠ” row ì—¬ëŸ¬ ê°œ ì¡´ì¬.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39594fcf",
   "metadata": {},
   "source": [
    "### ê²°ì¸¡ì¹˜ ëŒ€ì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e659a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ëƒ¥ dependencyë‘ dependencyì˜ ì œê³± ë‘ ê°œì˜ ë³€ìˆ˜ê°€ ë”°ë¡œ ì¡´ì¬í•¨..(ì™œ..?) -> dependenyì˜ ê²°ì¸¡ì¹˜ë¥¼ SQBdependencyì˜ ë£¨íŠ¸ë¡œ ëŒ€ì²´\n",
    "train['dependency'] = np.sqrt(train['SQBdependency'])  \n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d8272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# educationì—ì„œ 'no'ë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´\n",
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0  # edjefa: ì—¬ì„± ê°€ì¥ì˜ êµìœ¡ë°›ì€ ë…„ìˆ˜\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0  # edjefe: ë‹˜ìƒ ê°€ì¥ì˜ êµìœ¡ë°›ì€ ë…„ìˆ˜\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "# educationì´ 'yes'ì´ê³  ê·¸ ì‚¬ëŒì´ ê°€ì¥ì¼ ê²½ìš° escolari(êµìœ¡ë°›ì€ ë…„ìˆ˜)ë¡œ ëŒ€ì²´\n",
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# education='yes'ì¸ë° ê·¸ ì‚¬ëŒì´ ê°€ì¥ì´ ì•„ë‹Œ ê²½ìš° ê·¸ëƒ¥ 4ë¡œ ëŒ€ì²´...\n",
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# intíƒ€ì…ìœ¼ë¡œ ë³€ê²½\n",
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")\n",
    "\n",
    "# edjefaì™€ edjefe ì¤‘ í° ê°’ ë³€ìˆ˜ ìƒì„±(ê°€ì¥ì˜ ì„±ë³„ê³¼ ìƒê´€ ì—†ì´ ê·¸ëƒ¥ ì´ êµìœ¡ ë…„ìˆ˜)\n",
    "train['edjef'] = np.max(train[['edjefa','edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa','edjefe']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "180c37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2a1, v18q1, rez_esc, meanduc, SQBmeanedëŠ” ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´\n",
    "train['v2a1']=train['v2a1'].fillna(0)\n",
    "test['v2a1']=test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1']=test['v18q1'].fillna(0)\n",
    "train['v18q1']=train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc']=train['rez_esc'].fillna(0)\n",
    "test['rez_esc']=test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81c8b0",
   "metadata": {},
   "source": [
    "### ë³€ìˆ˜ ì¶©ëŒ í•´ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8760d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v14a & sanitario1:í™”ì¥ì‹¤ ì¡´ì¬ ì—¬ë¶€(v14aëŠ” ìˆìœ¼ë©´ 1, sanitario1ì€ ì—†ìœ¼ë©´ 1) -> ì¶©ëŒì´ ìˆëŠ” ë³€ìˆ˜ê°€ ìˆìŒ\n",
    "# abastaguano: ë¬¼ ê³µê¸‰ ì—¬ë¶€(ì—†ì„ì‹œ 1) ë³€ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì¶©ëŒ í•´ê²°\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0 \n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a965050",
   "metadata": {},
   "source": [
    "### ì¸ì½”ë”© í•¨ìˆ˜ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69613a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "techo ì•ˆì˜ OHEê°€ ë¶ˆì™„ì „í•˜ë¯€ë¡œ ë¼ë²¨ ì¸ì½”ë”© ì „ì— ìƒˆë¡œìš´ ì¹¼ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤\n",
      "instlevel ì•ˆì˜ OHEê°€ ë¶ˆì™„ì „í•˜ë¯€ë¡œ ë¼ë²¨ ì¸ì½”ë”© ì „ì— ìƒˆë¡œìš´ ì¹¼ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤\n",
      "manual_elec ì•ˆì˜ OHEê°€ ë¶ˆì™„ì „í•˜ë¯€ë¡œ ë¼ë²¨ ì¸ì½”ë”© ì „ì— ìƒˆë¡œìš´ ì¹¼ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "\n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_  = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "\n",
    "    del xx, xx_func\n",
    "    return train_, test_\n",
    "\n",
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09af8be",
   "metadata": {},
   "source": [
    "### geo aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6983fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§€ì—­ë³„ ë³€ìˆ˜ë¥¼ ì¶”ê°€(ì§€ì—­ë³„ ë°”ë‹¥/ì²œì¥/ë²½/ì“°ë ˆê¸° ìˆ˜ê±° í˜„í™© ë“±..)\n",
    "\n",
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']  # ë²”ì£¼í˜• ë³€ìˆ˜\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']   # ë“±ê°„/ë¹„ìœ¨ ì²™ë„(ìˆ«ìí˜•)\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe],   # ì´ì‚°í˜•->ë²”ì£¼í˜• ë³€í™˜í•œê±¸ ë‹¤ì‹œ ë”ë¯¸í™”...(?)\n",
    "                                       columns=cols_2_ohe)],axis=1)\n",
    "\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)  # ë”ë¯¸ë³€ìˆ˜ì˜ í‰ê·  => ë¹„ìœ¨ ë‚˜íƒ€ëƒ„\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "782d1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18ì„¸ ì´ìƒ ì„±ì¸ ë³€ìˆ˜ ì¶”ê°€\n",
    "\n",
    "# train['num_over_18'] = 0\n",
    "# train['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "# train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "# train['num_over_18'] = train['num_over_18'].fillna(0)\n",
    "\n",
    "train['num_over_18'] = train['idhogar'].map(train[train['age'] >= 18].groupby('idhogar')['age'].count()).fillna(0).astype(int)\n",
    "\n",
    "# test['num_over_18'] = 0\n",
    "# test['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "# test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "# test['num_over_18'] = test['num_over_18'].fillna(0)\n",
    "\n",
    "test['num_over_18'] = test['idhogar'].map(train[train['age']>=18].groupby('idhogar')['age'].count()).fillna(0).astype(int)\n",
    "# ê¸°íƒ€ ë³€ìˆ˜ ì¶”ê°€...\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/df['r4t3'] # rent to people in household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms'] # rooms per person\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize'] # rent to household size\n",
    "    df['rent_to_over_18'] = df['v2a1']/df['num_over_18']\n",
    "    # some households have no one over 18, use the total rent for those\n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n",
    "    \n",
    "extract_features(train)    \n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df886aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì“¸ëª¨ì—†ëŠ” ë³€ìˆ˜ ë²„ë¦¬ê¸°\n",
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824597b",
   "metadata": {},
   "source": [
    "## data split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fb4bb",
   "metadata": {},
   "source": [
    "ê°€êµ¬ ë‹¨ìœ„ë¡œ split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6be3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.2, seed=None):\n",
    "    train2 = train.copy()\n",
    "\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)  # 20% ê°€êµ¬ ì¶”ì¶œ\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "\n",
    "    X_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "435b8d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       4\n",
       "2       4\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9552    2\n",
       "9553    2\n",
       "9554    2\n",
       "9555    2\n",
       "9556    2\n",
       "Name: Target, Length: 9557, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10bf1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=None)\n",
    "\n",
    "X = train.copy()\n",
    "X = train.query('parentesco1==1')   # ê°€ì¥ ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "y = X['Target'] - 1\n",
    "X = X.drop(['Target'], axis=1)\n",
    "\n",
    "train2 = X.copy()\n",
    "train_hhs = train2.idhogar\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households)*0.15),replace=False)   # ê°€êµ¬ ì¤‘ì—ì„œ ëœë¤í•˜ê²Œ 15% ì„ íƒ\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx] \n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "X_train = train2  # ê± ì´ë ‡ê²Œ ì“¸ê±°ë©´ ìœ„ì— ì½”ë“œëŠ” ì™œ ì“´ê±°ì§€?\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f52daec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6892df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì“¸ë°ì—†ëŠ” ë³€ìˆ˜ ë˜ ë“œë\n",
    "\n",
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN',\n",
    " 'agg18_estadocivil6_COUNT',\n",
    " 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT',\n",
    " 'agg18_parentesco11_COUNT',\n",
    " 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT',\n",
    " 'agg18_parentesco2_COUNT',\n",
    " 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT',\n",
    " 'agg18_parentesco5_COUNT',\n",
    " 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT',\n",
    " 'agg18_parentesco8_COUNT',\n",
    " 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4',\n",
    " 'geo_energcocinar_LE_1',\n",
    " 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0',\n",
    " 'geo_hogar_mayor',\n",
    " 'geo_manual_elec_LE_2',\n",
    " 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4',\n",
    " 'geo_pared_LE_5',\n",
    " 'geo_pared_LE_6',\n",
    " 'num_over_18',\n",
    " 'parentesco_LE',\n",
    " 'rez_esc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b91e1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_drop_cols = extra_drop_features + ['idhogar', 'parentesco1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc95b4",
   "metadata": {},
   "source": [
    "## Fit a voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70468681",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.5, 'colsample_bylevel': 1, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1)\n",
    "\n",
    "fit_params = {'early_stopping_rounds': 500,\n",
    "              'eval_metric': evaluate_macroF1_lgb,\n",
    "              'eval_set': [(X_train, y_train), (X_test, y_test)],\n",
    "              'verbose': False}\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate * np.power(0.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50   # ì™œ ìê¾¸ ë’¤ì—ì„œ ë”°ë¡œorë‹¤ì‹œ ì •ì˜í•˜ëŠ”ì§€ ëª¨ë¥´ê² ìŒ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5257d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold = True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        X_train, y_train, X_test, y_test, y_train_weight = split_data(X, y, sample_weight, households = train_households)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = split_data(X, y, None, households=train_households)\n",
    "\n",
    "    fit_params['eval_set'] = [(X_test, y_test)]\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n",
    "        best_cv = f1_score(y_test, estimator.predict(X_test), average=\"macro\")\n",
    "        print(\"Train F1:\", best_train)\n",
    "        print(\"Test F1:\", best_cv)\n",
    "        \n",
    "    # reject some estimators based on their performance on train and test sets\n",
    "    if threshold:\n",
    "        # if the valid score is very high we'll allow a little more leeway with the train scores\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "\n",
    "        # else recurse until we get a better one\n",
    "        else:\n",
    "            print(\"Unacceptable!!! Trying again...\")\n",
    "            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n",
    "    \n",
    "    else:\n",
    "        return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81495aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    '''\n",
    "    This implements the fit method of the VotingClassifier propagating fit_params\n",
    "    '''\n",
    "    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        \n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output'\n",
    "                                      ' classification is not supported.')\n",
    "\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
    "                             % self.voting)\n",
    "\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n",
    "                                 ' should be a list of (string, estimator)'\n",
    "                                 ' tuples')\n",
    "\n",
    "        if (self.weights is not None and\n",
    "                len(self.weights) != len(self.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d estimators'\n",
    "                             % (len(self.weights), len(self.estimators)))\n",
    "\n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is '\n",
    "                             'required to be a classifier!')\n",
    "\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n",
    "                                                 sample_weight=sample_weight, threshold=threshold, **fit_params)\n",
    "                for clf in clfs if clf is not None)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e081c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_b2k4a2hea3/croot/xgboost-split_1675457783214/work/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m(clfs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Train the final model with learning rate decay\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_drop_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m clf_final \u001b[38;5;241m=\u001b[39m vc\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m, in \u001b[0;36mVotingClassifierLGBM.fit\u001b[0;34m(self, X, y, sample_weight, threshold, **fit_params)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m, in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator1, X, y, sample_weight, threshold, **fit_params)\u001b[0m\n\u001b[1;32m     15\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m         _ \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator1, ExtraTreesClassifier) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator1, RandomForestClassifier):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py:186\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    189\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/callback.py:240\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 240\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m splited \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# into datasets\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# split up `test-error:0.1234`\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:2002\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dmat, evname \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[0;32m-> 2002\u001b[0m         feval_ret \u001b[38;5;241m=\u001b[39m \u001b[43mfeval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdmat\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feval_ret, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   2006\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m feval_ret:\n\u001b[1;32m   2007\u001b[0m                 \u001b[38;5;66;03m# pylint: disable=consider-using-f-string\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m, in \u001b[0;36mevaluate_macroF1_lgb\u001b[0;34m(predictions, truth)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_macroF1_lgb\u001b[39m(predictions, truth):\n\u001b[0;32m----> 4\u001b[0m     pred_labels \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     truth \u001b[38;5;241m=\u001b[39m truth\u001b[38;5;241m.\u001b[39mget_label()\n\u001b[1;32m      6\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m f1_score(truth, pred_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n",
    "    \n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "    \n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del(clfs)\n",
    "\n",
    "#Train the final model with learning rate decay\n",
    "_ = vc.fit(X_train.drop(xgb_drop_cols, axis=1, errors='ignore'), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "\n",
    "clf_final = vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542d993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
